{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deeplearning_image_classification.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HMXB6-bqfVA9MiNclt37KQEhqmuMzkYw","authorship_tag":"ABX9TyNyzpynJS94crGKsxJy5uV5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EYeF58Bkm_uy"},"source":["#@title Run this to import the right things\r\n","from __future__ import absolute_import\r\n","from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","import collections\r\n","import math\r\n","import os\r\n","import random\r\n","from six.moves import urllib\r\n","import io\r\n","import shutil\r\n","import sklearn.linear_model as sk\r\n","\r\n","from IPython.display import clear_output, Image, display, HTML\r\n","\r\n","\r\n","import tensorflow as tf\r\n","import tensorflow_hub as hub\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","import sklearn.metrics as sk_metrics\r\n","import time\r\n","from tensorflow.keras.applications.resnet50 import preprocess_input\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from keras import optimizers\r\n","\r\n","from keras.applications.inception_v3 import InceptionV3\r\n","from keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\r\n","from keras.preprocessing import image\r\n","from keras import regularizers\r\n","from keras.models import Model\r\n","from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\r\n","from keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M50xe-_6nhg9"},"source":["#@title Run this confusion matrix function\r\n","from sklearn.metrics import confusion_matrix\r\n","def plot_confusion_matrix(y_true, y_pred, classes,\r\n","                          normalize=False,\r\n","                          title=None,\r\n","                          cmap=plt.cm.Blues):\r\n","    \"\"\"\r\n","    This function prints and plots the confusion matrix.\r\n","    Normalization can be applied by setting `normalize=True`.\r\n","    \"\"\"\r\n","    if not title:\r\n","        if normalize:\r\n","            title = 'Normalized confusion matrix'\r\n","        else:\r\n","            title = 'Confusion matrix, without normalization'\r\n","\r\n","    # Compute confusion matrix\r\n","    cm = confusion_matrix(y_true, y_pred)\r\n","    # Only use the labels that appear in the data\r\n","    classes = classes\r\n","    if normalize:\r\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n","        print(\"Normalized confusion matrix\")\r\n","    else:\r\n","        print('Confusion matrix, without normalization')\r\n","\r\n","    print(cm)\r\n","\r\n","    fig, ax = plt.subplots()\r\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\r\n","    ax.figure.colorbar(im, ax=ax)\r\n","    # We want to show all ticks...\r\n","    ax.set(xticks=np.arange(cm.shape[1]),\r\n","           yticks=np.arange(cm.shape[0]),\r\n","           # ... and label them with the respective list entries\r\n","           xticklabels=classes, yticklabels=classes,\r\n","           title=title,\r\n","           ylabel='True label',\r\n","           xlabel='Predicted label')\r\n","\r\n","    # Rotate the tick labels and set their alignment.\r\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\r\n","             rotation_mode=\"anchor\")\r\n","\r\n","    # Loop over data dimensions and create text annotations.\r\n","    fmt = '.2f' if normalize else 'd'\r\n","    thresh = cm.max() / 2.\r\n","    for i in range(cm.shape[0]):\r\n","        for j in range(cm.shape[1]):\r\n","            ax.text(j, i, format(cm[i, j], fmt),\r\n","                    ha=\"center\", va=\"center\",\r\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\r\n","    fig.tight_layout()\r\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCjbnWJ1_pgW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609992991536,"user_tz":-330,"elapsed":19649,"user":{"displayName":"pavithra p","photoUrl":"","userId":"08361351501613083362"}},"outputId":"8d7cbd2d-47b2-47ae-c2ef-dcee836db43a"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nnIsNvEF_urN"},"source":["\r\n","## set train, validation, and test paths\r\n","train_path = '/content/gdrive/MyDrive/classifier/data/train' \r\n","validation_path = '/content/gdrive/MyDrive/classifier/data/validation'\r\n","test_path = '/content/gdrive/MyDrive/classifier/data/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdmoMAFO_0lM"},"source":["train_batches  = ImageDataGenerator().flow_from_directory(\r\n","    train_path, target_size=(224,224), classes = ['brokenpick', 'contamination', 'doublepick', 'hole', 'pinhole', 'slub', 'stain'], batch_size = 50)\r\n","\r\n","validation_batches  = ImageDataGenerator().flow_from_directory(\r\n","    validation_path, target_size=(224,224), classes = ['brokenpick', 'contamination', 'doublepick', 'hole', 'pinhole', 'slub', 'stain'], batch_size = 10)\r\n","\r\n","test_batches  = ImageDataGenerator().flow_from_directory(\r\n","    test_path, target_size=(224,224), classes = ['brokenpick', 'contamination', 'doublepick', 'hole', 'pinhole', 'slub', 'stain'], batch_size = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvH3dz9q_1am"},"source":["\r\n","#take a look at output of the generators\r\n","\r\n","for data_batch, labels_batch in train_batches:\r\n","    print('data batch shape:', data_batch.shape)\r\n","    print('labels batch shape:', labels_batch.shape)\r\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKlzbecb_4N-"},"source":["##Sample images\r\n","\r\n","img_path = '/content/gdrive/MyDrive/classifier/data/test/slub/d1 (13).jpg' \r\n","img = image.load_img(img_path, target_size=(224,224))\r\n","\r\n","plt.imshow(img)\r\n","\r\n","print(\"slub\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9fljGTx_8Ac"},"source":["img_path = '/content/gdrive/MyDrive/classifier/data/test/doublepick/img12.jpg' \r\n","img = image.load_img(img_path, target_size=(224,224))\r\n","\r\n","plt.imshow(img)\r\n","\r\n","print(\"doublepick\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47II5byRzaKW"},"source":["Sequential model:"]},{"cell_type":"code","metadata":{"id":"mN7JJUo8__p-"},"source":["from keras import layers\r\n","from keras import models\r\n","\r\n","model = models.Sequential()\r\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\r\n","                        input_shape=(224, 224, 3)))\r\n","model.add(layers.MaxPooling2D((2, 2)))\r\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n","model.add(layers.MaxPooling2D((2, 2)))\r\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n","model.add(layers.MaxPooling2D((2, 2)))\r\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n","model.add(layers.MaxPooling2D((2, 2)))\r\n","model.add(layers.Flatten())\r\n","model.add(layers.Dense(512, activation='relu'))\r\n","model.add(layers.Dense(7, activation='softmax'))\r\n","model.summary()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYUjh7GNADel"},"source":["## set steps per epoch for train\r\n","train_filenames = train_batches.filenames\r\n","steps_train = len(train_filenames)/train_batches.batch_size\r\n","\r\n","## set steps per epoch for validation\r\n","validation_filenames = validation_batches.filenames\r\n","steps_valid = len(validation_filenames)/validation_batches.batch_size\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=optimizers.RMSprop(lr=1e-4),\r\n","              metrics=['acc'])\r\n","fit_generator1 = model.fit_generator(\r\n","      train_batches,\r\n","      steps_per_epoch=steps_train,\r\n","      epochs=30,\r\n","      validation_data=validation_batches,\r\n","      validation_steps=steps_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlsaSlLyAG5d"},"source":["\r\n","import matplotlib.pyplot as plt\r\n","\r\n","acc = fit_generator1.history['acc']\r\n","val_acc = fit_generator1.history['val_acc']\r\n","loss = fit_generator1.history['loss']\r\n","val_loss = fit_generator1.history['val_loss']\r\n","\r\n","epochs = range(len(acc))\r\n","\r\n","plt.plot(epochs, acc, 'bo', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', label='Validation acc', color = 'r')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","plt.figure()\r\n","\r\n","plt.plot(epochs, loss, 'bo', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', label='Validation loss', color = 'r')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNCBIziTpUnX"},"source":["model2 = models.Sequential()\r\n","model2.add(layers.Conv2D(32, (3, 3), activation='relu',\r\n","                        input_shape=(224, 224, 3)))\r\n","model2.add(layers.MaxPooling2D((2, 2)))\r\n","model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n","model2.add(layers.MaxPooling2D((2, 2)))\r\n","model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n","model2.add(layers.MaxPooling2D((2, 2)))\r\n","model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n","model2.add(layers.MaxPooling2D((2, 2)))\r\n","model2.add(layers.Flatten())\r\n","model2.add(layers.Dense(512, activation='relu'))\r\n","model2.add(Dropout(0.5))\r\n","model2.add(layers.Dense(7 , activation='softmax'))\r\n","model2.summary()\r\n","model.save('fabrick_basic_model_dl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-l3ArvmALXV"},"source":["train_datagen = ImageDataGenerator( \r\n","         rescale=1./255,\r\n","         brightness_range=[0.5, 0.5], \r\n","         horizontal_flip=True,\r\n","         vertical_flip=True)\r\n","        \r\n","\r\n","test_datagen = ImageDataGenerator(rescale=1./255)\r\n","\r\n","train_generator = train_datagen.flow_from_directory(\r\n","        train_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=50,\r\n","        class_mode='categorical')\r\n","\r\n","validation_generator = test_datagen.flow_from_directory(\r\n","        validation_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=10,\r\n","        class_mode='categorical')\r\n","\r\n","## set steps per epoch for train\r\n","train_filenames = train_generator.filenames\r\n","steps_train = len(train_filenames)/train_generator.batch_size\r\n","\r\n","## set steps per epoch for validation\r\n","validation_filenames = validation_generator.filenames\r\n","steps_valid = len(validation_filenames)/validation_generator.batch_size\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=optimizers.RMSprop(lr=1e-6),\r\n","              metrics=['acc'])\r\n","\r\n","fit_generator_3 = model.fit_generator(\r\n","        train_generator,\r\n","        steps_per_epoch=steps_train,\r\n","        epochs=50,\r\n","        validation_data=validation_generator,\r\n","        validation_steps=steps_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_u4wAHwWsoBR"},"source":["model.save('fabrick_basic_model_dl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCVkm3AkSjih"},"source":["# interp = ClassificationInterpretation.from_learner(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMqrydhRSnNn"},"source":["# interp.plot_top_losses(16,figsize=(12,13))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WGQosy-OArMf"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","acc = fit_generator_3.history['acc']\r\n","val_acc = fit_generator_3.history['val_acc']\r\n","loss = fit_generator_3.history['loss']\r\n","val_loss = fit_generator_3.history['val_loss']\r\n","\r\n","epochs = range(len(acc))\r\n","\r\n","plt.plot(epochs, acc, 'bo', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', label='Validation acc', color = 'r')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","plt.figure()\r\n","\r\n","plt.plot(epochs, loss, 'bo', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', label='Validation loss', color = 'r')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Dc-NBN5DTVu"},"source":["model_test_datagen = ImageDataGenerator(rescale=1./255)\r\n","\r\n","model_test_generator = model_test_datagen.flow_from_directory(\r\n","        test_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=2,\r\n","        shuffle = False,\r\n","        class_mode='categorical')\r\n","\r\n","filenames = model_test_generator.filenames\r\n","nb_samples = len(filenames)\r\n","\r\n","model_predict = model.predict_generator(model_test_generator,steps = nb_samples, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnkwsDfKfWXT"},"source":["y_true = model_test_generator.classes\r\n","y_pred = model_predict.argmax(axis=1)\r\n","plot_confusion_matrix(y_true, y_pred, classes=['brokenpick', 'contamination', 'doublepick', 'hole', 'pinhole', 'slub', 'stain'],\r\n","                      title='Confusion matrix, without normalization')\r\n","#plots(test_images, titles=test_labels)\r\n","print(filenames)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KPLAwBWPGxiS"},"source":["VGG16 Model"]},{"cell_type":"code","metadata":{"id":"xkoM0WeHF1BC"},"source":["#@title Run this to import the right things\r\n","from __future__ import absolute_import\r\n","from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","import collections\r\n","import math\r\n","import os\r\n","import random\r\n","from six.moves import urllib\r\n","import io\r\n","import shutil\r\n","import keras\r\n","from IPython.display import clear_output, Image, display, HTML\r\n","\r\n","\r\n","import tensorflow as tf\r\n","import tensorflow_hub as hub\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","import sklearn.metrics as sk_metrics\r\n","import time\r\n","from tensorflow.keras.applications.resnet50 import preprocess_input\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","from keras.applications.inception_v3 import InceptionV3\r\n","from keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\r\n","from keras.preprocessing import image\r\n","from keras import regularizers\r\n","from keras.models import Model\r\n","from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\r\n","from keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqfP1q7gF2JW"},"source":["from keras.applications.vgg16 import VGG16\r\n","vgg_model = VGG16(weights = 'imagenet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXLf9oC2F84E"},"source":["vgg_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pw5PZTOhGADh"},"source":["from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","\r\n","vgg_transfer_base_model = Sequential()\r\n","\r\n","for layer in vgg_model.layers[:-1]:\r\n","  vgg_transfer_base_model.add(layer)\r\n","  \r\n","vgg_transfer_base_model.layers.pop()\r\n","for layer in vgg_transfer_base_model.layers:\r\n","  layer.trainable=False\r\n","\r\n","vgg_transfer_base_model.add(Dense(512, activation = 'relu'))\r\n","vgg_transfer_base_model.add(Dropout(0.5))\r\n","vgg_transfer_base_model.add(Dense(7, activation='softmax'))\r\n","vgg_transfer_base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7rzmGpWGInx"},"source":["## data augmentation datagen\r\n","vgg_train_datagen_do = ImageDataGenerator(\r\n","         rescale=1./255,\r\n","         brightness_range=[0.5, 0.5], \r\n","         horizontal_flip=True,\r\n","         vertical_flip=True)\r\n","\r\n","## test generator, required for prediction\r\n","vgg_test_datagen_do = ImageDataGenerator(rescale=1./255)\r\n","\r\n","## train generator\r\n","vgg_train_generator_do = vgg_train_datagen_do.flow_from_directory(\r\n","        train_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=25,\r\n","        class_mode='categorical')\r\n","\r\n","## validation generator\r\n","vgg_validation_generator_do = vgg_test_datagen_do.flow_from_directory(\r\n","        validation_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=10,\r\n","        class_mode='categorical')\r\n","\r\n","## compile model\r\n","vgg_transfer_base_model.compile(loss='categorical_crossentropy',\r\n","              optimizer=optimizers.RMSprop(lr=1e-9),\r\n","              metrics=['acc'])\r\n","\r\n","\r\n","## set steps per epoch for train\r\n","train_filenames_do = vgg_train_generator_do.filenames\r\n","steps_train_do = len(train_filenames_do)/vgg_train_generator_do.batch_size\r\n","\r\n","## set steps per epoch for validation\r\n","validation_filenames_do = vgg_validation_generator_do.filenames\r\n","steps_valid_do = len(validation_filenames_do)/vgg_validation_generator_do.batch_size\r\n","\r\n","## fit model\r\n","vgg_base_fit_generator_do = vgg_transfer_base_model.fit_generator(\r\n","        vgg_train_generator_do,\r\n","        steps_per_epoch=steps_train_do,\r\n","        epochs=50,\r\n","        validation_data=vgg_validation_generator_do,\r\n","        validation_steps=steps_valid_do,\r\n","        verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"og_MIDkqGJdz"},"source":["vgg_transfer_base_model.save('vgg_model_dropout')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFlsfiS9GPUj"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","acc = vgg_base_fit_generator_do.history['acc']\r\n","val_acc = vgg_base_fit_generator_do.history['val_acc']\r\n","loss = vgg_base_fit_generator_do.history['loss']\r\n","val_loss = vgg_base_fit_generator_do.history['val_loss']\r\n","\r\n","epochs = range(len(acc))\r\n","\r\n","plt.plot(epochs, acc, 'bo', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', label='Validation acc', color = 'r')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","plt.figure()\r\n","\r\n","plt.plot(epochs, loss, 'bo', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', label='Validation loss', color = 'r')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M3t5vByGQSO"},"source":["vgg_test_generator_do = vgg_test_datagen_do.flow_from_directory(\r\n","        test_path,\r\n","        target_size=(224, 224),\r\n","        batch_size=1,\r\n","        shuffle = False,\r\n","        class_mode='categorical')\r\n","\r\n","filenames_do = vgg_test_generator_do.filenames\r\n","nb_samples_do = len(filenames_do)\r\n","\r\n","predict_do = vgg_transfer_base_model.predict_generator(vgg_test_generator_do,steps = nb_samples_do, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2FR0EsXGUWS"},"source":["do_y_true = vgg_test_generator_do.classes\r\n","do_y_pred = predict_do.argmax(axis=1)\r\n","plot_confusion_matrix(do_y_true, do_y_pred, classes=['brokenpick', 'contamination', 'doublepick', 'hole', 'pinhole', 'slub', 'stain'],\r\n","                      title='Confusion matrix, without normalization')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmdTjysBGZvB"},"source":[""],"execution_count":null,"outputs":[]}]}